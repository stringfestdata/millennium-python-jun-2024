{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "This notebook will explain the following topics and concepts:\n",
    "\n",
    "- **Built in Statistical Functions** \n",
    "\n",
    "- **apply** and **applymap**\n",
    "\n",
    "- **Calculating the return of an investment**\n",
    "  - Normalized prices\n",
    "  - Cumulative returns\n",
    "  - Log returns\n",
    "\n",
    "- **Correlation & Covariance**\n",
    "  - Calculating\n",
    "  - visualizing\n",
    "  - rolling correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Simple DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serA = stats.randint(1,100).rvs(15)\n",
    "serB = stats.randint(1000, 5000).rvs(15)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['A'] = serA\n",
    "df['B'] = serB\n",
    "\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built in Statistical Functions\n",
    "\n",
    "The following functions can all be applied to a Series.\n",
    "\n",
    "As a column is a Series, they can all be applied to a column or columns of a DataFrame or even an entire DataFrame\n",
    "\n",
    "- Simple Functions\n",
    "- Accumulators\n",
    "- General Purpose Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Functions\n",
    "\n",
    "\n",
    "- count() \n",
    "- min() \n",
    "- max() \n",
    "- sum() \n",
    "- mean()\n",
    "- median() \n",
    "- std() \n",
    "- describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()\n",
    "df.min()\n",
    "df.max()\n",
    "df.sum()\n",
    "df.sum().sum()\n",
    "df.mean()\n",
    "df.median()\n",
    "df.std()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accumulators\n",
    "\n",
    "- cumsum()\n",
    "- cummin()\n",
    "- cummax()\n",
    "- cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cumsum().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cummin().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cummax().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cumprod().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General purpose Functions\n",
    "\n",
    "There are also a few general purpose functions\n",
    "\n",
    "- diff()  - difference between adjacent values\n",
    "- pct_change() - percentage change between adjacent values\n",
    "- idxmin() - numerical index of minimum value in series (Series begin at index 0)\n",
    "- idxmax() - numerical index of maximum value in series\n",
    "- skew()\n",
    "- kurt()\n",
    "- quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_change().transpose()\n",
    "df.diff().transpose()\n",
    "df.idxmax()\n",
    "df.idxmin()\n",
    "df.skew()\n",
    "df.kurt()\n",
    "df.quantile(q=[0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying functions to Series and DataFrames\n",
    "\n",
    "- You can easily apply arbitrary functions to DataFrames.\n",
    "\n",
    "- Use the **apply()** function\n",
    "\n",
    "- This method can be used to apply a function to a Series, Column, Columns or an entire DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDF():\n",
    "    cols = ['A', 'B', 'C']\n",
    "    rows = ['Row 1', 'Row 2', 'Row 3', 'Row 4']\n",
    "    data = np.arange(12).reshape(4,3)\n",
    "\n",
    "    return pd.DataFrame(data=data, columns=cols, index=rows)\n",
    "\n",
    "df = makeDF()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply across a row\n",
    "\n",
    "Use the `sum()` method to sum each element of a **row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DataFrame\n",
    "df = makeDF()\n",
    "\n",
    "cols = ['A', 'B', 'C']\n",
    "def custom_sum(row):\n",
    "    return row.sum()\n",
    "\n",
    "df['Row Result'] = df[cols].apply(custom_sum, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply along a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DataFrame\n",
    "df = makeDF()\n",
    "\n",
    "df.loc['Col Result'] = df.apply(custom_sum, axis=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply\n",
    "The default axis is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DataFrame\n",
    "df = makeDF()\n",
    "\n",
    "def multiply_by_2(val):\n",
    "    return val * 2\n",
    "\n",
    "df['Row Result'] = df['C'].apply(multiply_by_2)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DataFrame\n",
    "df = makeDF()\n",
    "\n",
    "# The lambda equivalent for the sum of each row of a DataFrame:\n",
    "df['Row Result'] = df[cols].apply(lambda x:x.sum(), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DataFrame\n",
    "df = makeDF()\n",
    "\n",
    "# The lambda equivalent for the sum of each column of a DataFrame:\n",
    "df.loc['Col Result']= df.apply(lambda x:x.sum(), axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lambda equivalent for multiply by 2 on a Series\n",
    "df['Row Result'] = df['C'].apply(lambda x:x*2)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions\n",
    "\n",
    "$y = max(0, cos(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = makeDF()\n",
    "\n",
    "def foo(x):\n",
    "    y = np.cos(x) \n",
    "    return y if y > 0 else 0\n",
    "\n",
    "df.map(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that have parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = makeDF()\n",
    "\n",
    "def bar(x, e):\n",
    "    return x + (e**2)\n",
    "\n",
    "df['A'].apply(func=bar,e=2)\n",
    "\n",
    "df.apply(func=bar,e=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the return of an investment\n",
    "\n",
    "\n",
    "**Common Front Office Calculations**\n",
    "- Normalized prices\n",
    "- daily returns\n",
    "- the log of returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some data from yahoo finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If yfinance is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "df_stocks =  yf.download(tickers='TSLA MSFT AAPL', start='2018-01-01')['Adj Close'].copy()\n",
    "\n",
    "df_stocks.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with plotting the price is that its difficult to gauge how well the security has performed.\n",
    "\n",
    "Better to first scale the prices to 1 and then plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar problem, when comparing 2 or more investments, also best to scale all prices to 1 and then plot, this makes for an easier comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Prices\n",
    "\n",
    "The difference between price(t0) and price (t+1)\n",
    "\n",
    "This is the same as cumulative daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_Normed = df_stocks/df_stocks.iloc[0]\n",
    "\n",
    "df_stocks_Normed.plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with normalized prices is that its static. \n",
    "\n",
    "Change the dates of the Dataframe and the original problem is still present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_Normed['2021-Aug':'2023'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Returns\n",
    "\n",
    "- When calculating the return of an investment or position, the product of daily returns can be used.\n",
    "\n",
    "- This allows a direct comparison to be made between different instruments\n",
    "\n",
    "- When backtesting technical analysis you will be employing this measure to compare a simple trading strategy against market performance.\n",
    "\n",
    "- This is a very simple value to arrive at\n",
    "\n",
    "- price / price(t-1)\n",
    "\n",
    "- price(t-1) arrived at by using the time shift functions\n",
    "\n",
    "- Use the `cumprod()` function to arrive at the payoff\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cumprod` to convert daily returns to stock performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_daily_returns =  df_stocks / df_stocks.shift(1)\n",
    "\n",
    "df_stocks_daily_returns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_daily_returns.cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_daily_returns['2012':'2020'].cumprod().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log of the Daily Returns\n",
    "\n",
    "- Used more frequently than product of returns (above)\n",
    "\n",
    "- When calculating the return of an investment or position, an accumulation of the log of daily returns is used.\n",
    "\n",
    "- This allows a direct comparison to be made between different instruments\n",
    "\n",
    "- When backtesting technical analysis you will be employing this measure to compare a simple trading strategy against market performance.\n",
    "\n",
    "- This is a very simple value to arrive at\n",
    "\n",
    "- `log (price / price(t-1))`\n",
    "\n",
    "- Use a combination of `apply()` and  `cumsum()` function to arrive at the payoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_log_returns = np.log(df_stocks / df_stocks.shift(1))\n",
    "\n",
    "df_stocks_log_returns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_log_returns.cumsum().apply(np.exp).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_log_returns['2012':'2020'].cumsum().apply(np.exp).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Co-Variance\n",
    "\n",
    "- Pandas has some convenient built-ins for calculating these.\n",
    "\n",
    "- We'll Use some previous datasets for demonstration.\n",
    "\n",
    "- Calculate the correlation and covariance between the daily percentage change of the Adjusted Close price of FANG Stocks and Gold Futures.\n",
    "\n",
    "- Display the correlation\n",
    "\n",
    "- Calculate the covariance of the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If yfinance is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download(tickers='^GSPC JPM IBM F GLD BZ=F', start='2000-01-01')['Adj Close'].copy()\n",
    "\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - Correlation and Covariance change over time\n",
    "df.loc['2023'].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate Daily Percentage Change\n",
    "\n",
    "**Note** \n",
    "\n",
    "These correlations are different from the prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_change = df.pct_change(fill_method=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_change.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_change.loc['2023'].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate covariance\n",
    "\n",
    "- Use the **cov()** function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_change.cov()\n",
    "\n",
    "\n",
    "# Covariance\n",
    "df_pct_change.loc['2017'].cov()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a scatter plot to display a visual of correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "p = scatter_matrix(df_pct_change.loc['2017'], alpha=0.9, hist_kwds={'bins':50}, figsize=(18,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_corr = df_pct_change.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D mask / filter\n",
    "mask = np.zeros(df_corr.shape, dtype=bool)\n",
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get triangle Upper Indices\n",
    "mask[np.triu_indices(len(mask))] = True\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask out the upper part of the heat map\n",
    "sns.heatmap(df_corr,annot=True,mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rolling Correlations\n",
    "\n",
    "ax = df_pct_change['F'].rolling(window=252).corr(df_pct_change['IBM']).plot(figsize=(10, 6))  \n",
    "\n",
    "# This line shows the corralation of both over the entire time period\n",
    "# Note how the rolling correlation is much more telling\n",
    "\n",
    "corr_full = df_pct_change[['F']].corrwith(df_pct_change['IBM']),\n",
    "\n",
    "ax.axhline(corr_full, c='r');  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "752a8dbf0d2606d0e4a8fd11745a0f3cf206e4848a02eb7bb5eda5c098d7f642"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
